{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference 작업 순서\n",
    "### 1. condition으로 줄 midi파일을 마련한다.\n",
    "### 2. input_file과 output_file을 지정한다.\n",
    "### 3. 새로만들 token 갯수 N을 지정하고 출력한다.\n",
    "### 4. 출력한 결과가 마음에 들면 해당 파일을 input_file로 지정하고 2를 다시 실행한다.\n",
    "### 5. 출력한 결과가 마음에 안들면 3작업을 다시 실행한다.\n",
    "### 6. 원하는 분량이 나올 때 까지 2-5작업을 반복한다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_vocab=390,n_ctx=512,n_embd=512,n_head=16,n_layer=8,n_time=2000\n"
     ]
    }
   ],
   "source": [
    "IntervalDim = 100\n",
    "\n",
    "VelocityDim = 32\n",
    "VelocityOffset = IntervalDim\n",
    "\n",
    "NoteOnDim = NoteOffDim = 128\n",
    "NoteOnOffset = IntervalDim + VelocityDim\n",
    "NoteOffOffset = IntervalDim + VelocityDim + NoteOnDim\n",
    "\n",
    "CCDim = 2\n",
    "CCOffset = IntervalDim + VelocityDim + NoteOnDim + NoteOffDim\n",
    "\n",
    "EventDim = IntervalDim + VelocityDim + NoteOnDim + NoteOffDim + CCDim # 390\n",
    "\n",
    "Time = 2000\n",
    "\n",
    "EmbeddingDim = 512\n",
    "\n",
    "HeadDim = 32\n",
    "Heads = 16\n",
    "ContextDim = HeadDim * Heads # 512\n",
    "\n",
    "Layers = 8\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.training import HParams\n",
    "\n",
    "def default_hparams():\n",
    "    return HParams(\n",
    "        n_vocab=EventDim,\n",
    "        n_ctx=ContextDim,\n",
    "        n_embd=EmbeddingDim,\n",
    "        n_head=Heads,\n",
    "        n_layer=Layers,\n",
    "        n_time=Time,\n",
    "    )\n",
    "\n",
    "hparams = default_hparams()\n",
    "print(hparams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### input file (conditional)과 결과를 출력할 output file을 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = 'theme223332023023.mid'\n",
    "output_file = \"theme2233320230230.mid\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### input file을 event 단위로 parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.00000000e+00 1.00000000e+00 3.80000000e+01 6.40000000e+01]\n",
      " [3.86363636e-02 1.00000000e+00 4.10000000e+01 6.80000000e+01]\n",
      " [8.63636364e-02 1.00000000e+00 4.50000000e+01 7.20000000e+01]\n",
      " ...\n",
      " [2.36793182e+02 0.00000000e+00 7.60000000e+01 0.00000000e+00]\n",
      " [2.36802273e+02 1.00000000e+00 7.50000000e+01 7.20000000e+01]\n",
      " [2.36861364e+02 1.00000000e+00 7.60000000e+01 8.00000000e+01]]\n"
     ]
    }
   ],
   "source": [
    "import mido\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def get_eventlist(data_file):\n",
    "    ON = 1\n",
    "    OFF = 0\n",
    "    CC = 2\n",
    "\n",
    "    midi = mido.MidiFile(data_file)\n",
    "\n",
    "    current_time = 0\n",
    "    eventlist = []\n",
    "    cc = False\n",
    "    for msg in midi:\n",
    "        #print(msg)\n",
    "        current_time += msg.time\n",
    "\n",
    "         # NOTE ON CASE\n",
    "        if msg.type is 'note_on' and msg.velocity > 0:\n",
    "            event = [current_time, ON, msg.note, msg.velocity]\n",
    "            eventlist.append(event)\n",
    "\n",
    "         # NOTE OFF CASE        \n",
    "        elif msg.type is 'note_off' or (msg.type is 'note_on' and msg.velocity == 0):\n",
    "            event = [current_time, OFF, msg.note, msg.velocity]\n",
    "            eventlist.append(event)\n",
    "            \n",
    "        if msg.type is 'control_change':\n",
    "            \n",
    "            if msg.control != 64:\n",
    "                continue\n",
    "            \n",
    "            if cc == False and msg.value > 0:\n",
    "                cc = True\n",
    "                event = [current_time, CC, 0, 1]\n",
    "                eventlist.append(event)\n",
    "                \n",
    "            elif cc == True and msg.value == 0:\n",
    "                cc = False\n",
    "                event = [current_time, CC, 0, 0]\n",
    "                eventlist.append(event)\n",
    "                \n",
    "    eventlist = np.array(eventlist)\n",
    "    return eventlist\n",
    "\n",
    "eventlist = get_eventlist(input_file)\n",
    "print(eventlist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### event list를 시각화하여 보여줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x shape :  (20597,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1800x1500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa.display\n",
    "\n",
    "def get_data(eventlist):\n",
    "    data = eventlist\n",
    "    \n",
    "    # absolute time to relative interval\n",
    "    data[1:, 0] = data[1:, 0] - data[:-1, 0]\n",
    "    data[0, 0] = 0\n",
    "    \n",
    "    # discretize interval into IntervalDim\n",
    "    data[:, 0] = np.clip(np.round(data[:, 0] * IntervalDim), 0, IntervalDim - 1)\n",
    "    \n",
    "    eventlist = []\n",
    "    for d in data:\n",
    "        # append interval\n",
    "        interval = d[0]\n",
    "        eventlist.append(interval)\n",
    "    \n",
    "        # note on case\n",
    "        if d[1] == 1:\n",
    "            velocity = (d[3] / 128) * VelocityDim + VelocityOffset\n",
    "            note = d[2] + NoteOnOffset\n",
    "            eventlist.append(velocity)\n",
    "            eventlist.append(note)\n",
    "            \n",
    "        # note off case\n",
    "        elif d[1] == 0:\n",
    "            note = d[2] + NoteOffOffset\n",
    "            eventlist.append(note)\n",
    "        # CC\n",
    "        elif d[1] == 2:\n",
    "            event = CCOffset + d[3]\n",
    "            eventlist.append(event)\n",
    "            \n",
    "    eventlist = np.array(eventlist).astype(np.int)\n",
    "    if len(eventlist) < Time:\n",
    "        eventlist = np.pad(eventlist, (Time - len(eventlist), 0), mode='constant')\n",
    "    \n",
    "    return eventlist\n",
    "    \n",
    "x = get_data(eventlist)\n",
    "print('x shape : ', x.shape)\n",
    "    \n",
    "roll = np.zeros([len(x), EventDim])\n",
    "for t, _x in enumerate(x):\n",
    "    roll[t, _x] = 1\n",
    "\n",
    "plt.figure(figsize=[18, 15])\n",
    "librosa.display.specshow(roll.T)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model에 관련된 함수들"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shape_list(x):\n",
    "    \"\"\"Deal with dynamic shape in tensorflow cleanly.\"\"\"\n",
    "    static = x.shape.as_list()\n",
    "    dynamic = tf.shape(x)\n",
    "    return [dynamic[i] if s is None else s for i, s in enumerate(static)]\n",
    "\n",
    "def softmax(x, temperature=1.0, axis=-1):\n",
    "    x = x - tf.reduce_max(x, axis=axis, keepdims=True)\n",
    "    ex = tf.exp(x / temperature)\n",
    "    return ex / tf.reduce_sum(ex, axis=axis, keepdims=True)\n",
    "\n",
    "def gelu(x):\n",
    "    return 0.5*x*(1+tf.tanh(np.sqrt(2/np.pi)*(x+0.044715*tf.pow(x, 3))))\n",
    "\n",
    "def norm(x, scope, *, axis=-1, epsilon=1e-5):\n",
    "    \"\"\"Normalize to mean = 0, std = 1, then do a diagonal affine transform.\"\"\"\n",
    "    with tf.variable_scope(scope):\n",
    "        n_state = x.shape[-1].value\n",
    "        g = tf.get_variable('g', [n_state], initializer=tf.constant_initializer(1))\n",
    "        b = tf.get_variable('b', [n_state], initializer=tf.constant_initializer(0))\n",
    "        u = tf.reduce_mean(x, axis=axis, keepdims=True)\n",
    "        s = tf.reduce_mean(tf.square(x-u), axis=axis, keepdims=True)\n",
    "        x = (x - u) * tf.rsqrt(s + epsilon)\n",
    "        x = x*g + b\n",
    "        return x\n",
    "\n",
    "def split_states(x, n):\n",
    "    \"\"\"Reshape the last dimension of x into [n, x.shape[-1]/n].\"\"\"\n",
    "    *start, m = shape_list(x)\n",
    "    return tf.reshape(x, start + [n, m//n])\n",
    "\n",
    "def merge_states(x):\n",
    "    \"\"\"Smash the last two dimensions of x into a single dimension.\"\"\"\n",
    "    *start, a, b = shape_list(x)\n",
    "    return tf.reshape(x, start + [a*b])\n",
    "\n",
    "def conv1d(x, scope, nf, *, w_init_stdev=0.02):\n",
    "    with tf.variable_scope(scope):\n",
    "        *start, nx = shape_list(x)\n",
    "        w = tf.get_variable('w', [1, nx, nf], initializer=tf.random_normal_initializer(stddev=w_init_stdev))\n",
    "        b = tf.get_variable('b', [nf], initializer=tf.constant_initializer(0))\n",
    "        c = tf.reshape(tf.matmul(tf.reshape(x, [-1, nx]), tf.reshape(w, [-1, nf]))+b, start+[nf])\n",
    "        return c\n",
    "\n",
    "def attention_mask(nd, ns, *, dtype):\n",
    "    \"\"\"1's in the lower triangle, counting from the lower right corner.\n",
    "    Same as tf.matrix_band_part(tf.ones([nd, ns]), -1, ns-nd), but doesn't produce garbage on TPUs.\n",
    "    \"\"\"\n",
    "    i = tf.range(nd)[:,None]\n",
    "    j = tf.range(ns)\n",
    "    m = i >= j - ns + nd\n",
    "    return tf.cast(m, dtype)\n",
    "\n",
    "\n",
    "def attn(x, scope, n_state, *, hparams):\n",
    "    assert x.shape.ndims == 3  # Should be [batch, sequence, features]\n",
    "    assert n_state % hparams.n_head == 0\n",
    "\n",
    "    def split_heads(x):\n",
    "        # From [batch, sequence, features] to [batch, heads, sequence, features]\n",
    "        return tf.transpose(split_states(x, hparams.n_head), [0, 2, 1, 3])\n",
    "\n",
    "    def merge_heads(x):\n",
    "        # Reverse of split_heads\n",
    "        return merge_states(tf.transpose(x, [0, 2, 1, 3]))\n",
    "\n",
    "    def mask_attn_weights(w):\n",
    "        # w has shape [batch, heads, dst_sequence, src_sequence], where information flows from src to dst.\n",
    "        _, _, nd, ns = shape_list(w)\n",
    "        b = attention_mask(nd, ns, dtype=w.dtype)\n",
    "        b = tf.reshape(b, [1, 1, nd, ns])\n",
    "        w = w*b - tf.cast(1e10, w.dtype)*(1-b)\n",
    "        return w\n",
    "    \n",
    "    def relative_attn(q):\n",
    "        # q have shape [batch, heads, sequence, features]\n",
    "        batch, heads, sequence, features = shape_list(q)\n",
    "        E = tf.get_variable('E', [heads, sequence, features])\n",
    "        # [heads, batch, sequence, features]\n",
    "        q_ = tf.transpose(q, [1, 0, 2, 3])\n",
    "        # [heads, batch * sequence, features]\n",
    "        q_ = tf.reshape(q_, [heads, batch * sequence, features])\n",
    "        # [heads, batch * sequence, sequence]\n",
    "        rel = tf.matmul(q_, E, transpose_b=True)\n",
    "        # [heads, batch, sequence, sequence]\n",
    "        rel = tf.reshape(rel, [heads, batch, sequence, sequence])\n",
    "        # [heads, batch, sequence, 1+sequence]\n",
    "        rel = tf.pad(rel, ((0, 0), (0, 0), (0, 0), (1, 0)))\n",
    "        # [heads, batch, sequence+1, sequence]\n",
    "        rel = tf.reshape(rel, (heads, batch, sequence+1, sequence))\n",
    "        # [heads, batch, sequence, sequence]\n",
    "        rel = rel[:, :, 1:]\n",
    "        # [batch, heads, sequence, sequence]\n",
    "        rel = tf.transpose(rel, [1, 0, 2, 3])\n",
    "        return rel\n",
    "        \n",
    "    def multihead_attn(q, k, v):\n",
    "        # q, k, v have shape [batch, heads, sequence, features]\n",
    "        w = tf.matmul(q, k, transpose_b=True)\n",
    "        w = w + relative_attn(q)\n",
    "        w = w * tf.rsqrt(tf.cast(v.shape[-1].value, w.dtype))\n",
    "\n",
    "        w = mask_attn_weights(w)\n",
    "        w = softmax(w)\n",
    "        a = tf.matmul(w, v)\n",
    "        return a\n",
    "\n",
    "    with tf.variable_scope(scope):\n",
    "        c = conv1d(x, 'c_attn', n_state*3)\n",
    "        q, k, v = map(split_heads, tf.split(c, 3, axis=2))\n",
    "        present = tf.stack([k, v], axis=1)\n",
    "\n",
    "        a = multihead_attn(q, k, v)\n",
    "        a = merge_heads(a)\n",
    "        a = conv1d(a, 'c_proj', n_state)\n",
    "        return a, present\n",
    "\n",
    "\n",
    "def mlp(x, scope, n_state, *, hparams):\n",
    "    with tf.variable_scope(scope):\n",
    "        nx = x.shape[-1].value\n",
    "        h = gelu(conv1d(x, 'c_fc', n_state))\n",
    "        h2 = conv1d(h, 'c_proj', nx)\n",
    "        return h2\n",
    "\n",
    "\n",
    "def block(x, scope, *, hparams):\n",
    "    with tf.variable_scope(scope):\n",
    "        nx = x.shape[-1].value\n",
    "        a, present = attn(norm(x, 'ln_1'), 'attn', nx, hparams=hparams)\n",
    "        x = x + a\n",
    "        m = mlp(norm(x, 'ln_2'), 'mlp', nx*4, hparams=hparams)\n",
    "        x = x + m\n",
    "        return x, present\n",
    "\n",
    "def expand_tile(value, size):\n",
    "    \"\"\"Add a new axis of given size.\"\"\"\n",
    "    value = tf.convert_to_tensor(value, name='value')\n",
    "    ndims = value.shape.ndims\n",
    "    return tf.tile(tf.expand_dims(value, axis=0), [size] + [1]*ndims)\n",
    "\n",
    "def model(hparams, X, scope='model', reuse=False):\n",
    "    with tf.variable_scope(scope, reuse=reuse):\n",
    "        results = {}\n",
    "        batch, sequence = shape_list(X)\n",
    "\n",
    "        wte = tf.get_variable('wte', [hparams.n_vocab, hparams.n_embd],\n",
    "                             initializer=tf.random_normal_initializer(stddev=0.02))\n",
    "        h = tf.gather(wte, X)\n",
    "\n",
    "        # Transformer\n",
    "        presents = []\n",
    "        for layer in range(hparams.n_layer):\n",
    "            h, present = block(h, 'h%d' % layer, hparams=hparams)\n",
    "            presents.append(present)\n",
    "        results['present'] = tf.stack(presents, axis=1)\n",
    "        h = norm(h, 'ln_f')\n",
    "\n",
    "        # Language model loss.  Do tokens <n predict token n?\n",
    "        h_flat = tf.reshape(h, [batch*sequence, hparams.n_embd])\n",
    "        logits = tf.matmul(h_flat, wte, transpose_b=True)\n",
    "        logits = tf.reshape(logits, [batch, sequence, hparams.n_vocab])\n",
    "        results['logits'] = logits\n",
    "        return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model과 session을 만듬. 적당한 temperature를 조정할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_vocab=390,n_ctx=512,n_embd=512,n_head=16,n_layer=8,n_time=2000\n",
      "graph create\n"
     ]
    }
   ],
   "source": [
    "hparams = default_hparams()\n",
    "print(hparams)\n",
    "\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "X = tf.placeholder(tf.int32, [None, hparams.n_time])\n",
    "Y = tf.placeholder(tf.int32, [None, hparams.n_time])\n",
    "\n",
    "X_onehot = tf.one_hot(X, axis=2, depth=hparams.n_vocab)\n",
    "\n",
    "logits = model(hparams, X)['logits']\n",
    "probs = softmax(logits, temperature=0.95)\n",
    "dist = tf.distributions.Categorical(probs=probs[:, -1])\n",
    "sample = dist.sample()\n",
    "\n",
    "'''\n",
    "Session Open\n",
    "'''\n",
    "\n",
    "\n",
    "# GPU number to use\n",
    "gpu_options = tf.GPUOptions(visible_device_list=\"1\")\n",
    "sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "print('graph create')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save파일 불러옴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1012 18:25:12.693712 140644774278976 deprecation.py:323] From /home/scpark/.conda/envs/ai/lib/python3.7/site-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model restored. save/gpt2-cc-interval100-attention2000-midi/model.ckpt-142150\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.contrib.slim as slim\n",
    "from tensorflow.python import pywrap_tensorflow\n",
    "\n",
    "load_dir = 'save/gpt2-cc-interval100-attention2000-midi'\n",
    "\n",
    "def get_variables_from_checkpoint_file(file_name):\n",
    "    variables = []\n",
    "    reader = pywrap_tensorflow.NewCheckpointReader(file_name)\n",
    "\n",
    "    var_to_shape_map = reader.get_variable_to_shape_map()\n",
    "    for key in sorted(var_to_shape_map):\n",
    "        variables.append((key, var_to_shape_map[key]))\n",
    "\n",
    "    return variables\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "if True:\n",
    "    restore_file = tf.train.latest_checkpoint(load_dir)\n",
    "    if restore_file is not None:\n",
    "        try:\n",
    "            saver.restore(sess, restore_file)\n",
    "            print(\"Model restored.\", restore_file)\n",
    "        except:\n",
    "            saved_variables = get_variables_from_checkpoint_file(restore_file)\n",
    "            model_variables = slim.get_variables_to_restore()\n",
    "            restore_variables = []\n",
    "            for model_variable in model_variables:\n",
    "                for saved_variable_name, saved_variable_shape in saved_variables:\n",
    "                    model_variable_name = model_variable.name.split(\":\")[0]\n",
    "                    if saved_variable_name == model_variable_name and tuple(saved_variable_shape) == model_variable.shape:\n",
    "                        restore_variables.append(model_variable)\n",
    "\n",
    "            init_saver = tf.train.Saver(restore_variables)\n",
    "            init_saver.restore(sess, restore_file)\n",
    "            print(\"Model partially restored.\")\n",
    "    else:\n",
    "        print('model not exist.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### N에다 출력할 token갯수를 입력 후 실행하면 output_file에 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0 116 170 ...   0   0   0]]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a0189f9e3ca48079951f9da379e3de1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-86f237d49daa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0m_sample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_inputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mTime\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0m_inputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_sample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ai/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 950\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    951\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ai/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1171\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1172\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1173\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1174\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ai/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1350\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ai/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1354\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1355\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1356\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1357\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ai/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1339\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1340\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1341\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ai/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1427\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1428\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1429\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1431\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "N = 2000\n",
    "\n",
    "_inputs = np.zeros([1, len(x) + N], dtype=np.int32)\n",
    "_inputs[:, :len(x)] = x[None, :]\n",
    "print(_inputs)\n",
    "\n",
    "for i in tqdm(range(len(x), len(x) + N)):\n",
    "\n",
    "    _sample, _prob = sess.run([sample, probs], feed_dict={X: _inputs[:, i-Time:i]})\n",
    "    _inputs[:, i] = _sample \n",
    "\n",
    "print(_inputs.shape)\n",
    "\n",
    "class Event():\n",
    "    def __init__(self, time, note, cc, on, velocity):\n",
    "        self.time = time\n",
    "        self.note = note\n",
    "        self.on = on\n",
    "        self.cc = cc\n",
    "        self.velocity = velocity\n",
    "\n",
    "    def get_event_sequence(self):\n",
    "        return [self.time, self.note, int(self.on)]\n",
    "\n",
    "class Note():\n",
    "    def __init__(self):\n",
    "        self.pitch = 0\n",
    "        self.start_time = 0\n",
    "        self.end_time = 0\n",
    "\n",
    "event_list = []\n",
    "time = 0\n",
    "event = None\n",
    "\n",
    "#EventDim = IntervalDim + VelocityDim + NoteOnDim + NoteOffDim # 388\n",
    "\n",
    "for _input in _inputs[0]:\n",
    "    # interval\n",
    "    if _input < IntervalDim: \n",
    "        time += _input\n",
    "        event = Event(time, 0, False, 0, 0)\n",
    "\n",
    "    # velocity\n",
    "    elif _input < NoteOnOffset:\n",
    "        if event is None:\n",
    "            continue\n",
    "        event.velocity = (_input - VelocityOffset) / VelocityDim * 128\n",
    "        #print('velocity : ', event.velocity)\n",
    "\n",
    "    # note on\n",
    "    elif _input < NoteOffOffset:\n",
    "        if event is None:\n",
    "            continue\n",
    "\n",
    "        event.note = _input - NoteOnOffset\n",
    "        event.on = True\n",
    "        event_list.append(event)\n",
    "        #event_list.append(Event(event.time + 100, event.note, False))\n",
    "        event = None\n",
    "\n",
    "    # note off\n",
    "    elif _input < CCOffset:\n",
    "        if event is None:\n",
    "            continue\n",
    "        event.note = _input - NoteOffOffset\n",
    "        event.on = False\n",
    "        event_list.append(event)\n",
    "        event = None\n",
    "\n",
    "    ## CC\n",
    "    else:\n",
    "        if event is None:\n",
    "            continue\n",
    "        event.cc = True\n",
    "        on = _input - CCOffset == 1\n",
    "        event.on = on\n",
    "        #print(on)\n",
    "        event_list.append(event)\n",
    "        event = None\n",
    "\n",
    "import midi\n",
    "# Instantiate a MIDI Pattern (contains a list of tracks)\n",
    "pattern = midi.Pattern()\n",
    "# Instantiate a MIDI Track (contains a list of MIDI events)\n",
    "track = midi.Track()\n",
    "# Append the track to the pattern\n",
    "pattern.append(track)\n",
    "\n",
    "prev_time = 0\n",
    "pitches = [None for _ in range(128)]\n",
    "for event in event_list:\n",
    "    tick = int((event.time - prev_time) * 4.35)\n",
    "    prev_time = event.time\n",
    "\n",
    "    # case NOTE:\n",
    "    if not event.cc:\n",
    "        if event.on:\n",
    "            if pitches[event.note] is not None:\n",
    "                # Instantiate a MIDI note off event, append it to the track\n",
    "                off = midi.NoteOffEvent(tick=0, pitch=event.note)\n",
    "                track.append(off)\n",
    "                pitches[event.note] = None\n",
    "\n",
    "            # Instantiate a MIDI note on event, append it to the track\n",
    "            on = midi.NoteOnEvent(tick=tick, velocity=int(event.velocity), pitch=event.note)\n",
    "            track.append(on)\n",
    "            pitches[event.note] = prev_time\n",
    "        else:\n",
    "            # Instantiate a MIDI note off event, append it to the track\n",
    "            off = midi.NoteOffEvent(tick=tick, pitch=event.note)\n",
    "            track.append(off)\n",
    "            pitches[event.note] = None\n",
    "\n",
    "    # case CC:\n",
    "    elif event.cc:\n",
    "        if event.on:\n",
    "            cc = midi.ControlChangeEvent(tick=tick, control=64, value=64)\n",
    "        else:\n",
    "            cc = midi.ControlChangeEvent(tick=tick, control=64, value=0)\n",
    "\n",
    "        track.append(cc)\n",
    "\n",
    "    for pitch in range(128):\n",
    "        if pitches[pitch] is not None and pitches[pitch] + 100 < prev_time:\n",
    "            #print('here')\n",
    "            off = midi.NoteOffEvent(tick=0, pitch=pitch)\n",
    "            track.append(off)\n",
    "            pitches[pitch] = None \n",
    "\n",
    "\n",
    "# Add the end of track event, append it to the track\n",
    "eot = midi.EndOfTrackEvent(tick=1)\n",
    "track.append(eot)\n",
    "# Print out the pattern\n",
    "#print(pattern)\n",
    "# Save the pattern to disk\n",
    "midi.write_midifile(output_file, pattern)\n",
    "\n",
    "print('done')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
